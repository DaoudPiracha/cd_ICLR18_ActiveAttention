{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "---- Instead of 10-way classification its performs BINARY CLASSIFICATION over image pairs\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "require 'nn'\n",
    "model_utils = require 'model_utils'\n",
    "dofile './provider.lua'\n",
    "c = require 'trepl.colorize'\n",
    "require 'image'\n",
    "\n",
    "cmd_params = {}\n",
    "----- from the opt settings ------\n",
    "cmd_params.save = 'logs'\n",
    "cmd_params.batchSize = 128\n",
    "cmd_params.learningRate = 1\n",
    "cmd_params.learningRateDecay = 1e-7\n",
    "cmd_params.weightDecay = 0.0005\n",
    "cmd_params.momentum = 0.9\n",
    "cmd_params.epochStep = 100\n",
    "cmd_params.model_local = 'vgg_conv'\n",
    "cmd_params.model_global = 'vgg_full'\n",
    "cmd_params.model_atten = 'atten'\n",
    "cmd_params.model_match = 'match'\n",
    "\n",
    "cmd_params.max_epoch = 1000\n",
    "cmd_params.backend = 'nn'\n",
    "cmd_params.type = 'cuda'\n",
    "----------------------------------\n",
    "cmd_params.name = 'experiment'\n",
    "cmd_params.gpumode = 1\n",
    "cmd_params.gpu_setDevice = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function cast(t)\n",
    "   if cmd_params.type == 'cuda' then\n",
    "      require 'cunn'\n",
    "        gpumode = cmd_params.gpumode\n",
    "        if gpumode==1 then\n",
    "            cutorch.setDevice(cmd_params.gpu_setDevice)\n",
    "        end\n",
    "      return t:cuda()\n",
    "   elseif cmd_params.type == 'float' then\n",
    "      return t:float()\n",
    "   elseif cmd_params.type == 'cl' then\n",
    "      require 'clnn'\n",
    "      return t:cl()\n",
    "   else\n",
    "      error('Unknown type '..cmd_params.type)\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "---- parse input params\n",
    "--cmd_params = cmd:parse(arg)\n",
    "--cmd:log(cmd_params.name .. '/log', cmd_params)\n",
    "\n",
    "local seed = 1234567890\n",
    "torch.manualSeed(seed)\n",
    "\n",
    "train_or_val = cmd_params.train_or_val\n",
    "im_path = cmd_params.im_dir\n",
    "gt_path = cmd_params.gt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "----Data Augmentation\n",
    "function data_aug(input)\n",
    "      local bs = input:size(1)\n",
    "      local flip_mask = torch.randperm(bs):le(bs/2)\n",
    "      for i=1,input:size(1) do\n",
    "        if flip_mask[i] == 1 then image.hflip(input[i], input[i]) end\n",
    "      end    \n",
    "    return input\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "require 'loadcaffe'\n",
    "model = loadcaffe.load('VGG_ILSVRC_16_layers_deploy.prototxt','VGG_ILSVRC_16_layers.caffemodel')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "----Initiation\n",
    "\n",
    "--1. Data loading\n",
    "print(c.blue '==>' ..' loading data')\n",
    "provider = torch.load 'provider.t7'\n",
    "provider.trainData.data = provider.trainData.data:float()\n",
    "provider.testData.data = provider.testData.data:float()\n",
    "\n",
    "unnorm_provider = torch.load 'unnorm_provider.t7'\n",
    "unnorm_provider.trainData.data = unnorm_provider.trainData.data:float()\n",
    "unnorm_provider.testData.data = unnorm_provider.testData.data:float()\n",
    "\n",
    "--2. Model creation\n",
    "\n",
    "------model A\n",
    "model_local = nn.Sequential()\n",
    "model_local:add(cast(nn.Copy('torch.FloatTensor', torch.type(cast(torch.Tensor())))))\n",
    "model_local:add(cast(dofile('models/'..cmd_params.model_local..'.lua')))\n",
    "model_local:get(1).updateGradInput = function(input) return end\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "   require 'cudnn'\n",
    "   cudnn.convert(model_local:get(2), cudnn)\n",
    "end\n",
    "\n",
    "model_global = nn.Sequential()\n",
    "model_global:add(cast(dofile('models/'..cmd_params.model_global..'.lua')))\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(model_local:get(1), cudnn)\n",
    "end\n",
    "\n",
    "model_atten = nn.Sequential()\n",
    "model_atten:add(cast(dofile('models/'..cmd_params.model_atten..'.lua')))\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(model_atten:get(1),cudnn)\n",
    "end\n",
    "\n",
    "------Common Model -------- MLP for context-vector matching\n",
    "model_match = nn.Sequential()\n",
    "model_match:add(cast(dofile('models/' ..cmd_params.model_match..'.lua')))\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(model_match:get(1), 'cudnn')\n",
    "end\n",
    "\n",
    "------model B\n",
    "model_local2 = model_local:clone('weight','bias','gradWeight','gradBias')\n",
    "joint_local = nn.Sequential():add(model_local):add(model_local2)\n",
    "\n",
    "model_global2 = model_global:clone('weight','bias','gradWeight','gradBias')\n",
    "joint_global = nn.Sequential():add(model_global):add(model_global2)\n",
    "\n",
    "model_atten2 = model_atten:clone('weight','bias','gradWeight','gradBias')\n",
    "joint_atten = nn.Sequential():add(model_atten):add(model_atten2)\n",
    "\n",
    "model_all = {}\n",
    "table.insert(model_all, joint_local)\n",
    "table.insert(model_all, joint_global)\n",
    "table.insert(model_all, joint_atten)\n",
    "table.insert(model_all, model_match)\n",
    "\n",
    "params, grad_params = model_utils.combine_all_parameters(model_all)\n",
    "print(params:size())\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "--3. Criterion\n",
    "print(c.blue'==>' ..' setting criterion')\n",
    "criterion = cast(nn.CrossEntropyCriterion())\n",
    "\n",
    "--4. Testing and saving\n",
    "confusion = optim.ConfusionMatrix(2)\n",
    "print('Will save at '..cmd_params.save)\n",
    "paths.mkdir(cmd_params.save)\n",
    "testLogger = optim.Logger(paths.concat(cmd_params.save, 'test.log'))\n",
    "testLogger:setNames{'% mean class accuracy (train set)', '% mean class accuracy (test set)'}\n",
    "testLogger.showPlot = false\n",
    "\n",
    "\n",
    "--5. Learning settings\n",
    "print(c.blue'==>' ..' configuring optimizer')\n",
    "optimState = {\n",
    "  learningRate = cmd_params.learningRate,\n",
    "  weightDecay = cmd_params.weightDecay,\n",
    "  momentum = cmd_params.momentum,\n",
    "  learningRateDecay = cmd_params.learningRateDecay,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[\n",
    "pl, gpl = joint_local:getParameters()\n",
    "print(pl:size())\n",
    "\n",
    "pg, gpg = joint_global:getParameters()\n",
    "print(pg:size())\n",
    "\n",
    "pa, gpa = joint_atten:getParameters()\n",
    "print(pa:size())\n",
    "\n",
    "pm,pgm = model_match:getParameters()\n",
    "print(pm:size())\n",
    "]]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "--Training\n",
    "function train()\n",
    "    \n",
    "    model_local:training(); model_local2:training()\n",
    "    model_global:training(); model_global2:training()\n",
    "    model_atten:training(); model_atten2:training()\n",
    "    model_match:training()\n",
    "    \n",
    "    epoch = epoch or 1\n",
    "    \n",
    "    if epoch % cmd_params.epochStep == 0 then optimState.learningRate = optimState.learningRate/2 end\n",
    "    print(c.blue '==>'..\" online epoch # \" .. epoch .. ' [batchSize = ' .. cmd_params.batchSize .. ']')\n",
    " \n",
    "\n",
    "    local targets = cast(torch.FloatTensor(cmd_params.batchSize))\n",
    "    local targets2 = cast(torch.FloatTensor(cmd_params.batchSize))\n",
    "    local indices = torch.randperm(provider.trainData.data:size(1)):long():split(cmd_params.batchSize)\n",
    "    -- remove last element so that all the batches have equal size\n",
    "    indices[#indices] = nil\n",
    "    print(#indices)\n",
    "    \n",
    "    local tic = torch.tic()\n",
    "    ---------- the entire epoch run\n",
    "    for t,v in ipairs(indices) do\n",
    "        if(t==#indices) then\n",
    "            break\n",
    "        end\n",
    "        local t2, v2 = next(indices,t)        \n",
    "        xlua.progress(t, #indices)\n",
    "        \n",
    "        ------gather images and labels for two adj splits\n",
    "        --1. image\n",
    "        --inputs = provider.trainData.data:index(1,v)\n",
    "        --inputs2 = provider.trainData.data:index(1,v2)\n",
    "        --2. data augmentation\n",
    "        --inputs = data_aug(inputs)\n",
    "        --inputs2 = data_aug(inputs2)\n",
    "        --3. unnormed image        \n",
    "        --unnorm_inputs = unnorm_provider.trainData.data:index(1,v)\n",
    "        --unnorm_inputs2 = unnorm_provider.trainData.data:index(1,v2)\n",
    "        --4. labels\n",
    "        targets:copy(provider.trainData.labels:index(1,v))\n",
    "        targets2:copy(provider.trainData.labels:index(1,v2))\n",
    "        --------------------------------------------------\n",
    "        ------compare for 0 or 1 labels\n",
    "        local a = torch.eq(targets,targets2)  ---a for adhoc\n",
    "        \n",
    "        ------select the pairs with label-1\n",
    "        local targets_sel1 = targets[a:eq(1)]\n",
    "        local targets2_sel1 = targets2[a:eq(1)]\n",
    "        \n",
    "        local v_sel1 = v:cuda()[a:eq(1)]\n",
    "        local v2_sel1 = v2:cuda()[a:eq(1)]\n",
    "        \n",
    "        local inputs_sel1 = provider.trainData.data:index(1,v_sel1:long())\n",
    "        local inputs2_sel1 = provider.trainData.data:index(1,v2_sel1:long())\n",
    "        inputs_sel1 = data_aug(inputs_sel1)\n",
    "        inputs2_sel1 = data_aug(inputs2_sel1)\n",
    "        local unnorminputs_sel1 = unnorm_provider.trainData.data:index(1,v_sel1:long())\n",
    "        local unnorminputs2_sel1 = unnorm_provider.trainData.data:index(1,v2_sel1:long())\n",
    "\n",
    "        --print(targets_sel1[1])\n",
    "        --print(targets2_sel1[1])\n",
    "        --itorch.image(unnorminputs_sel1[1])\n",
    "        --itorch.image(unnorminputs2_sel1[1])\n",
    "        len1 = targets_sel1:size()\n",
    "        \n",
    "        ------select the pairs with label-0\n",
    "        local targets_sel0= targets[a:eq(0)]\n",
    "        local targets2_sel0 = targets2[a:eq(0)]\n",
    "        targets_sel0 = targets_sel0[{{1,len1[1]}}]     ---clip\n",
    "        targets2_sel0 = targets2_sel0[{{1,len1[1]}}]   ---clip \n",
    "        \n",
    "        local v_sel0 = v:cuda()[a:eq(0)]\n",
    "        local v2_sel0 = v2:cuda()[a:eq(0)]\n",
    "        v_sel0 = v_sel0[{{1,len1[1]}}]    ---clip\n",
    "        v2_sel0 = v2_sel0[{{1,len1[1]}}]  ---clip\n",
    "        \n",
    "        local inputs_sel0 = provider.trainData.data:index(1,v_sel0:long())\n",
    "        local inputs2_sel0 = provider.trainData.data:index(1,v2_sel0:long())\n",
    "        inputs_sel0 = data_aug(inputs_sel0)\n",
    "        inputs2_sel0 = data_aug(inputs2_sel0)\n",
    "        local unnorminputs_sel0 = unnorm_provider.trainData.data:index(1,v_sel0:long())\n",
    "        local unnorminputs2_sel0 = unnorm_provider.trainData.data:index(1,v2_sel0:long())\n",
    "\n",
    "        --print(targets_sel0[1])\n",
    "        --print(targets2_sel0[1])\n",
    "        --itorch.image(unnorminputs_sel0[1])\n",
    "        --itorch.image(unnorminputs2_sel0[1])\n",
    "        --len0 = targets_sel0:size()\n",
    "                \n",
    "        ---------Randomly combine data and labels of the 2 categories (0 and 1)\n",
    "        local total_inputs = torch.cat(inputs_sel0, inputs_sel1,1)\n",
    "        local total_inputs2 = torch.cat(inputs2_sel0, inputs2_sel1,1)\n",
    "        \n",
    "        local total_targets = torch.cat(targets_sel0, targets_sel1,1)\n",
    "        local total_targets2 = torch.cat(targets2_sel0, targets2_sel1,1)\n",
    "        local total_gnd = (torch.eq(total_targets, total_targets2))+1\n",
    "        \n",
    "        --print(total_gnd:size())\n",
    "        --print(total_inputs:size())\n",
    "        --print(total_inputs2:size())\n",
    "        \n",
    "        --print(total_gnd[10])\n",
    "        --itorch.image(total_inputs[10])\n",
    "        --itorch.image(total_inputs2[10])\n",
    "        ----------------------------------------------------------------------- \n",
    "        local feval = function(x)\n",
    "              if x ~= params then params:copy(x) end\n",
    "                  grad_params:zero()\n",
    "\n",
    "                  ---------forward\n",
    "                  local lfeat = model_local:forward(total_inputs)\n",
    "            --print(lfeat:size())\n",
    "            --print(lfeat:max())\n",
    "                  local lfeat2 = model_local2:forward(total_inputs2)\n",
    "            --print(lfeat2:size())\n",
    "            --print(lfeat2:max())\n",
    "            \n",
    "                  local gfeat = model_global:forward(lfeat)\n",
    "            --print(gfeat:size())\n",
    "                  local gfeat2 = model_global2:forward(lfeat2)\n",
    "            --print(gfeat2:size())\n",
    "                  \n",
    "                  local att_con = model_atten:forward({lfeat,gfeat2})\n",
    "            --print(att_con[1]:size())\n",
    "            --print(att_con[2]:size())\n",
    "                  local att_con2 = model_atten2:forward({lfeat2,gfeat})\n",
    "            \n",
    "                  local prediction = model_match:forward({att_con[2], att_con2[2]})\n",
    "            --print(prediction)\n",
    "            --print(total_gnd)\n",
    "                  local err = criterion:forward(prediction, total_gnd)\n",
    "            --print(err)\n",
    "            \n",
    "                  ---------backward            \n",
    "                  local df_pred = criterion:backward(prediction, total_gnd)\n",
    "            --print(df_pred)\n",
    "\n",
    "                  local df_context = model_match:backward({att_con[2], att_con2[2]}, df_pred)\n",
    "                  \n",
    "                  local df_feat = model_atten:backward({lfeat,gfeat2}, {att_con[1]:fill(0), df_context[1]})\n",
    "                  local df_feat2 = model_atten2:backward({lfeat2,gfeat}, {att_con2[1]:fill(0), df_context[2]})\n",
    "                  \n",
    "                  local df_lfeat = model_global:backward(lfeat, df_feat2[2])\n",
    "                  local df_lfeat2 = model_global2:backward(lfeat2, df_feat[2])\n",
    " \n",
    "                  model_local:backward(total_inputs,(df_feat[1]+df_lfeat)/2)\n",
    "                  model_local2:backward(total_inputs2,(df_feat2[1]+df_lfeat2)/2)\n",
    "                \n",
    "                  confusion:batchAdd(prediction, total_gnd)\n",
    "            \n",
    "                  return f,grad_params\n",
    "        end\n",
    "        optim.sgd(feval, params, optimState)\n",
    "\n",
    "    end\n",
    "    -------------\n",
    "  confusion:updateValids()\n",
    "  print(('Train accuracy: '..c.cyan'%.2f'..' %%\\t time: %.2f s'):format(confusion.totalValid * 100, torch.toc(tic)))\n",
    "\n",
    "  train_acc = confusion.totalValid * 100\n",
    "\n",
    "  confusion:zero()\n",
    "  epoch = epoch + 1\n",
    "    \n",
    "    print(torch.sum(model_local:get(2):get(1).gradBias - model_local2:get(2):get(1).gradBias))\n",
    "    print(torch.sum(model_global:get(1):get(3).bias - model_global:get(1):get(3).bias))\n",
    "    print(torch.sum(model_atten:get(1).modules[6].weight - model_atten2:get(1).modules[6].weight))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  -- disable flips, dropouts and batch normalization\n",
    "  model:evaluate()\n",
    "  print(c.blue '==>'..\" testing\")\n",
    "  local bs = 125\n",
    "  for i=1,provider.testData.data:size(1),bs do\n",
    "    local outputs = model:forward(provider.testData.data:narrow(1,i,bs))\n",
    "    confusion:batchAdd(outputs, provider.testData.labels:narrow(1,i,bs))\n",
    "  end\n",
    "\n",
    "  confusion:updateValids()\n",
    "  print('Test accuracy:', confusion.totalValid * 100)\n",
    "  \n",
    "  if testLogger then\n",
    "    paths.mkdir(cmd_params.save)\n",
    "    testLogger:add{train_acc, confusion.totalValid * 100}\n",
    "    testLogger:style{'-','-'}\n",
    "    testLogger:plot()\n",
    "\n",
    "    local base64im\n",
    "    do\n",
    "      os.execute(('convert -density 200 %s/test.log.eps %s/test.png'):format(cmd_params.save,cmd_params.save))\n",
    "      os.execute(('openssl base64 -in %s/test.png -out %s/test.base64'):format(cmd_params.save,cmd_params.save))\n",
    "      local f = io.open(cmd_params.save..'/test.base64')\n",
    "      if f then base64im = f:read'*all' end\n",
    "    end\n",
    "\n",
    "    local file = io.open(cmd_params.save..'/report.html','w')\n",
    "    file:write(([[\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "    <title>%s - %s</title>\n",
    "    <img src=\"data:image/png;base64,%s\">\n",
    "    <h4>optimState:</h4>\n",
    "    <table>\n",
    "    ]]):format(cmd_params.save,epoch,base64im))\n",
    "    for k,v in pairs(optimState) do\n",
    "      if torch.type(v) == 'number' then\n",
    "        file:write('<tr><td>'..k..'</td><td>'..v..'</td></tr>\\n')\n",
    "      end\n",
    "    end\n",
    "    file:write'</table><pre>\\n'\n",
    "    file:write(tostring(confusion)..'\\n')\n",
    "    file:write(tostring(model)..'\\n')\n",
    "    file:write'</pre></body></html>'\n",
    "    file:close()\n",
    "  end\n",
    "\n",
    "  -- save model every 50 epochs\n",
    "  if epoch % 50 == 0 then\n",
    "    local filename = paths.concat(cmd_params.save, 'model.net')\n",
    "    print('==> saving model to '..filename)\n",
    "    torch.save(filename, model:get(2):clearState())\n",
    "  end\n",
    "\n",
    "  confusion:zero()\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i=1,cmd_params.max_epoch do\n",
    "  train()\n",
    "  --test()\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "--[[\n",
    "local i=1\n",
    "while i <= n_training_instances do   --sj\n",
    "    inputAux, tensorGt, gt_labels = create_instance_with_class() --createInstance()\n",
    "    nInstancesPerImage = #gt_labels --tensorGt:nElement()/nPixels\n",
    "    if nInstancesPerImage>0 then\n",
    "        i=i+1\n",
    "        xlua.progress(i, n_training_instances)\n",
    "        target = tensorGt:resize(nInstancesPerImage,nPixels):t()\n",
    "\n",
    "        if(i%n_training_instances==0) then\n",
    "            itorch.image(inputAux)\n",
    "        end\n",
    "        -- do fwd/bwd and return loss, grad_params\n",
    "        local init_state_global = clone_list(init_state)\n",
    "\n",
    "        ------------ create closure to evaluate f(X) and df/dX----------------\n",
    "        local feval = function(x)\n",
    "            -- get new parameters\n",
    "            if x ~= params then\n",
    "               params:copy(x)\n",
    "            end\n",
    "\n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            local loss = 0\n",
    "            ------------------- forward pass -------------------\n",
    "            --inputAux = torch.reshape(inputAux, 1,3,side_size,side_size):float()\n",
    "            model8_1:training()\n",
    "            med_x = model8_1:forward(inputAux)\n",
    "            med2_x = model8_2:forward(med_x) \n",
    "            x = fork:forward(med2_x)\n",
    "            local rnn_state = {[0] = init_state_global}\n",
    "            local predictions_small = {}\n",
    "            local middle_predictions = {}\n",
    "            local predictions = {}\n",
    "            local rnn_iterations = math.min(seq_length, nInstancesPerImage+cmd_params.non_object_iterations) --+1)\n",
    "            local dictions = torch.Tensor(500*500, rnn_iterations)\n",
    "            local scores = torch.Tensor(rnn_iterations)           -- softmax outputs\n",
    "            if gpumode==1 then\n",
    "                dictions = dictions:cuda()\n",
    "                scores = scores:cuda()\n",
    "            end\n",
    "        end\n",
    "        ------------ create closure to evaluate f(X) and df/dX----------------\n",
    "        if i%summarize_results_after==0 then\n",
    "            testo = 1\n",
    "        end\n",
    "        optimMethod(feval, params, optimState)\n",
    "    end\n",
    "end\n",
    "time = sys.clock() - time\n",
    "time = time / n_training_instances\n",
    "print(\"\\n==> time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
    "--ProFi:stop()\n",
    "--ProFi:writeReport( 'profile.txt' )\n",
    "]]--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
