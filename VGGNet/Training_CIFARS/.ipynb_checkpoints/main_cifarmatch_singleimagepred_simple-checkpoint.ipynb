{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "---- Instead of 10-way classification its performs BINARY CLASSIFICATION over image pairs\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "require 'nn'\n",
    "model_utils = require 'model_utils'\n",
    "dofile './provider.lua'\n",
    "c = require 'trepl.colorize'\n",
    "require 'image'\n",
    "\n",
    "cmd_params = {}\n",
    "----- from the opt settings ------\n",
    "cmd_params.save = 'logs'\n",
    "cmd_params.batchSize = 128\n",
    "cmd_params.learningRate = 1\n",
    "cmd_params.learningRateDecay = 1e-6\n",
    "cmd_params.weightDecay = 0.0005\n",
    "cmd_params.momentum = 0.9\n",
    "cmd_params.epochStep = 100\n",
    "cmd_params.model_local = 'vgg_conv'\n",
    "cmd_params.model_global = 'vgg_full'\n",
    "cmd_params.model_atten = 'atten'\n",
    "cmd_params.model_match = 'match_singleimagepred'\n",
    "----------------------------------\n",
    "cmd_params.max_epoch = 1000\n",
    "cmd_params.backend = 'nn'\n",
    "cmd_params.type = 'cuda'\n",
    "----------------------------------\n",
    "cmd_params.gpumode = 1\n",
    "cmd_params.gpu_setDevice = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function cast(t)\n",
    "   if cmd_params.type == 'cuda' then\n",
    "      require 'cunn'\n",
    "        gpumode = cmd_params.gpumode\n",
    "        if gpumode==1 then\n",
    "            cutorch.setDevice(cmd_params.gpu_setDevice)\n",
    "        end\n",
    "      return t:cuda()\n",
    "   elseif cmd_params.type == 'float' then\n",
    "      return t:float()\n",
    "   elseif cmd_params.type == 'cl' then\n",
    "      require 'clnn'\n",
    "      return t:cl()\n",
    "   else\n",
    "      error('Unknown type '..cmd_params.type)\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local seed = 1234567890\n",
    "torch.manualSeed(seed)\n",
    "\n",
    "train_or_val = cmd_params.train_or_val\n",
    "im_path = cmd_params.im_dir\n",
    "gt_path = cmd_params.gt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "----Data Augmentation\n",
    "function data_aug(input)\n",
    "      local bs = input:size(1)\n",
    "      local flip_mask = torch.randperm(bs):le(bs/2)\n",
    "      for i=1,input:size(1) do\n",
    "        if flip_mask[i] == 1 then image.hflip(input[i], input[i]) end\n",
    "      end    \n",
    "    return input\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "--[[\n",
    "require 'loadcaffe'\n",
    "model = loadcaffe.load('VGG_ILSVRC_16_layers_deploy.prototxt','VGG_ILSVRC_16_layers.caffemodel')\n",
    "print(model)\n",
    "]]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "----Initiation\n",
    "\n",
    "--1. Data loading\n",
    "print(c.blue '==>' ..' loading data')\n",
    "provider = torch.load 'provider.t7'\n",
    "provider.trainData.data = provider.trainData.data:float()\n",
    "provider.testData.data = provider.testData.data:float()\n",
    "\n",
    "unnorm_provider = torch.load 'unnorm_provider.t7'\n",
    "unnorm_provider.trainData.data = unnorm_provider.trainData.data:float()\n",
    "unnorm_provider.testData.data = unnorm_provider.testData.data:float()\n",
    "\n",
    "--2. Model creation\n",
    "\n",
    "------model A\n",
    "model_local = nn.Sequential()\n",
    "model_local:add(cast(nn.Copy('torch.FloatTensor', torch.type(cast(torch.Tensor())))))\n",
    "model_local:add(cast(dofile('models/'..cmd_params.model_local..'.lua')))\n",
    "model_local:get(1).updateGradInput = function(input) return end\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "   require 'cudnn'\n",
    "   cudnn.convert(model_local:get(2), cudnn)\n",
    "end\n",
    "\n",
    "model_global = nn.Sequential()\n",
    "model_global:add(cast(dofile('models/'..cmd_params.model_global..'.lua')))\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(model_local:get(1), cudnn)\n",
    "end\n",
    "\n",
    "model_atten = nn.Sequential()\n",
    "model_atten:add(cast(dofile('models/'..cmd_params.model_atten..'.lua')))\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(model_atten:get(1),cudnn)\n",
    "end\n",
    "\n",
    "------Common Model -------- MLP for context-vector matching\n",
    "model_match = nn.Sequential()\n",
    "model_match:add(cast(dofile('models/' ..cmd_params.model_match..'.lua')))\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(model_match:get(1), 'cudnn')\n",
    "end\n",
    "\n",
    "------model B\n",
    "--[[\n",
    "model_local2 = model_local:clone('weight','bias','gradWeight','gradBias')\n",
    "joint_local = nn.Sequential():add(model_local):add(model_local2)\n",
    "\n",
    "model_global2 = model_global:clone('weight','bias','gradWeight','gradBias')\n",
    "joint_global = nn.Sequential():add(model_global):add(model_global2)\n",
    "\n",
    "model_atten2 = model_atten:clone('weight','bias','gradWeight','gradBias')\n",
    "joint_atten = nn.Sequential():add(model_atten):add(model_atten2)\n",
    "]]--\n",
    "\n",
    "model_all = {}\n",
    "table.insert(model_all, model_local)\n",
    "table.insert(model_all, model_global)\n",
    "--table.insert(model_all, model_atten)\n",
    "--table.insert(model_all, model_match)\n",
    "\n",
    "params, grad_params = model_utils.combine_all_parameters(model_all)\n",
    "print(params:size())\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "--3. Criterion\n",
    "print(c.blue'==>' ..' setting criterion')\n",
    "criterion = cast(nn.CrossEntropyCriterion())\n",
    "\n",
    "--4. Testing and saving\n",
    "confusion = optim.ConfusionMatrix(10)\n",
    "print('Will save at '..cmd_params.save)\n",
    "paths.mkdir(cmd_params.save)\n",
    "testLogger = optim.Logger(paths.concat(cmd_params.save, 'test.log'))\n",
    "testLogger:setNames{'% mean class accuracy (train set)', '% mean class accuracy (test set)'}\n",
    "testLogger.showPlot = false\n",
    "\n",
    "\n",
    "--5. Learning settings\n",
    "print(c.blue'==>' ..' configuring optimizer')\n",
    "optimState = {\n",
    "  learningRate = cmd_params.learningRate,\n",
    "  weightDecay = cmd_params.weightDecay,\n",
    "  momentum = cmd_params.momentum,\n",
    "  learningRateDecay = cmd_params.learningRateDecay,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[\n",
    "pl, gpl = joint_local:getParameters()\n",
    "print(pl:size())\n",
    "\n",
    "pg, gpg = joint_global:getParameters()\n",
    "print(pg:size())\n",
    "\n",
    "pa, gpa = joint_atten:getParameters()\n",
    "print(pa:size())\n",
    "\n",
    "pm,pgm = model_match:getParameters()\n",
    "print(pm:size())\n",
    "]]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "--Training\n",
    "function train()\n",
    "    \n",
    "    model_local:training(); \n",
    "    model_global:training(); \n",
    "    model_atten:training(); \n",
    "    model_match:training()\n",
    "    \n",
    "    epoch = epoch or 1\n",
    "    \n",
    "    if epoch % cmd_params.epochStep == 0 then optimState.learningRate = optimState.learningRate/2 end\n",
    "    print(c.blue '==>'..\" online epoch # \" .. epoch .. ' [batchSize = ' .. cmd_params.batchSize .. ']')\n",
    "\n",
    "    local targets = cast(torch.FloatTensor(cmd_params.batchSize))\n",
    "    local indices = torch.randperm(provider.trainData.data:size(1)):long():split(cmd_params.batchSize)\n",
    "    -- remove last element so that all the batches have equal size\n",
    "    indices[#indices] = nil\n",
    "    print(#indices)\n",
    "    \n",
    "    local tic = torch.tic()\n",
    "    ---------- the entire epoch run\n",
    "    for t,v in ipairs(indices) do\n",
    "        \n",
    "        xlua.progress(t, #indices)\n",
    "        ----gather images and labels for two adj splits\n",
    "        --1. image\n",
    "        inputs = provider.trainData.data:index(1,v)\n",
    "        --2. data augmentation\n",
    "        inputs = data_aug(inputs)\n",
    "        --3. unnormed image        \n",
    "        unnorm_inputs = unnorm_provider.trainData.data:index(1,v)\n",
    "        --4. labels\n",
    "        targets:copy(provider.trainData.labels:index(1,v))\n",
    "        \n",
    "        ----------------------------------------------------------------------- \n",
    "        \n",
    "        local feval = function(x)\n",
    "              if x ~= params then params:copy(x) end\n",
    "                  grad_params:zero()\n",
    "            \n",
    "                  ---------forward\n",
    "                  local lfeat = model_local:forward(inputs)\n",
    "            --print(lfeat:size())\n",
    "            --print(lfeat:max())              \n",
    "                  local prediction = model_global:forward(lfeat)\n",
    "            --[[\n",
    "                  local gfeat = model_global:forward(lfeat)\n",
    "            print(gfeat:size())                          \n",
    "          \n",
    "                local att_con = model_atten:forward({lfeat,gfeat})\n",
    "            print(att_con[1]:size())\n",
    "            print(att_con[2]:size())\n",
    "                  \n",
    "                  local prediction = model_match:forward(att_con[2])\n",
    "            ]]--           \n",
    "               local err = criterion:forward(prediction, targets)\n",
    "            --print(err)\n",
    "            \n",
    "            ---------backward            \n",
    "                  local df_pred = criterion:backward(prediction, targets)\n",
    "            --print(df_pred)\n",
    "            --[[\n",
    "                  local df_context = model_match:backward({att_con[2]}, df_pred)\n",
    "                  \n",
    "                  local df_feat = model_atten:backward({lfeat,gfeat}, {att_con[1]:fill(0), df_context})\n",
    "            ]]--                                \n",
    "                  local df_lfeat = model_global:backward(lfeat, df_pred)                  \n",
    "                  model_local:backward(inputs,df_lfeat)                                  \n",
    "            \n",
    "                  confusion:batchAdd(prediction, targets)\n",
    "            \n",
    "                  return f,grad_params\n",
    "        end\n",
    "        optim.sgd(feval, params, optimState)\n",
    "\n",
    "    end\n",
    "    -------------\n",
    "  confusion:updateValids()\n",
    "  print(('Train accuracy: '..c.cyan'%.2f'..' %%\\t time: %.2f s'):format(confusion.totalValid * 100, torch.toc(tic)))\n",
    "\n",
    "  train_acc = confusion.totalValid * 100\n",
    "\n",
    "  confusion:zero()\n",
    "  epoch = epoch + 1\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  -- disable flips, dropouts and batch normalization\n",
    "    model_local:evaluate()\n",
    "    model_global:evaluate() \n",
    "    model_atten:evaluate() \n",
    "    model_match:evaluate()\n",
    "    \n",
    "  print(c.blue '==>'..\" testing\")\n",
    "  local bs = 125\n",
    "  for i=1,provider.testData.data:size(1),bs do\n",
    "    local lfeat = model_local:forward(provider.testData.data:narrow(1,i,bs))\n",
    "    local prediction = model_global:forward(lfeat)\n",
    "        \n",
    "    confusion:batchAdd(prediction, provider.testData.labels:narrow(1,i,bs))\n",
    "  end\n",
    "\n",
    "  confusion:updateValids()\n",
    "  print('Test accuracy:', confusion.totalValid * 100)\n",
    "  \n",
    "  if testLogger then\n",
    "    paths.mkdir(cmd_params.save)\n",
    "    testLogger:add{train_acc, confusion.totalValid * 100}\n",
    "    testLogger:style{'-','-'}\n",
    "    testLogger:plot()\n",
    "\n",
    "    local base64im\n",
    "    do\n",
    "      os.execute(('convert -density 200 %s/test.log.eps %s/test.png'):format(cmd_params.save,cmd_params.save))\n",
    "      os.execute(('openssl base64 -in %s/test.png -out %s/test.base64'):format(cmd_params.save,cmd_params.save))\n",
    "      local f = io.open(cmd_params.save..'/test.base64')\n",
    "      if f then base64im = f:read'*all' end\n",
    "    end\n",
    "\n",
    "    local file = io.open(cmd_params.save..'/report.html','w')\n",
    "    file:write(([[\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "    <title>%s - %s</title>\n",
    "    <img src=\"data:image/png;base64,%s\">\n",
    "    <h4>optimState:</h4>\n",
    "    <table>\n",
    "    ]]):format(cmd_params.save,epoch,base64im))\n",
    "    for k,v in pairs(optimState) do\n",
    "      if torch.type(v) == 'number' then\n",
    "        file:write('<tr><td>'..k..'</td><td>'..v..'</td></tr>\\n')\n",
    "      end\n",
    "    end\n",
    "    file:write'</table><pre>\\n'\n",
    "    file:write(tostring(confusion)..'\\n')\n",
    "    file:write(tostring(model)..'\\n')\n",
    "    file:write'</pre></body></html>'\n",
    "    file:close()\n",
    "  end\n",
    "\n",
    "  -- save model every 50 epochs\n",
    "  if epoch % 50 == 0 then\n",
    "    local filename_loc = paths.concat(cmd_params.save, 'model_local.net')\n",
    "    print('==> saving model to '..filename_loc)\n",
    "    torch.save(filename_loc, model_local:get(2):clearState())\n",
    "        \n",
    "    local filename_glo = paths.concat(cmd_params.save, 'model_global.net')\n",
    "    print('==> saving model to '.. filename_glo)\n",
    "    torch.save(filename_glo, model_global:get(1):clearState())\n",
    "  end\n",
    "\n",
    "  confusion:zero()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i=1,cmd_params.max_epoch do\n",
    "  train()\n",
    "  test()\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "--[[\n",
    "local i=1\n",
    "while i <= n_training_instances do   --sj\n",
    "    inputAux, tensorGt, gt_labels = create_instance_with_class() --createInstance()\n",
    "    nInstancesPerImage = #gt_labels --tensorGt:nElement()/nPixels\n",
    "    if nInstancesPerImage>0 then\n",
    "        i=i+1\n",
    "        xlua.progress(i, n_training_instances)\n",
    "        target = tensorGt:resize(nInstancesPerImage,nPixels):t()\n",
    "\n",
    "        if(i%n_training_instances==0) then\n",
    "            itorch.image(inputAux)\n",
    "        end\n",
    "        -- do fwd/bwd and return loss, grad_params\n",
    "        local init_state_global = clone_list(init_state)\n",
    "\n",
    "        ------------ create closure to evaluate f(X) and df/dX----------------\n",
    "        local feval = function(x)\n",
    "            -- get new parameters\n",
    "            if x ~= params then\n",
    "               params:copy(x)\n",
    "            end\n",
    "\n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            local loss = 0\n",
    "            ------------------- forward pass -------------------\n",
    "            --inputAux = torch.reshape(inputAux, 1,3,side_size,side_size):float()\n",
    "            model8_1:training()\n",
    "            med_x = model8_1:forward(inputAux)\n",
    "            med2_x = model8_2:forward(med_x) \n",
    "            x = fork:forward(med2_x)\n",
    "            local rnn_state = {[0] = init_state_global}\n",
    "            local predictions_small = {}\n",
    "            local middle_predictions = {}\n",
    "            local predictions = {}\n",
    "            local rnn_iterations = math.min(seq_length, nInstancesPerImage+cmd_params.non_object_iterations) --+1)\n",
    "            local dictions = torch.Tensor(500*500, rnn_iterations)\n",
    "            local scores = torch.Tensor(rnn_iterations)           -- softmax outputs\n",
    "            if gpumode==1 then\n",
    "                dictions = dictions:cuda()\n",
    "                scores = scores:cuda()\n",
    "            end\n",
    "        end\n",
    "        ------------ create closure to evaluate f(X) and df/dX----------------\n",
    "        if i%summarize_results_after==0 then\n",
    "            testo = 1\n",
    "        end\n",
    "        optimMethod(feval, params, optimState)\n",
    "    end\n",
    "end\n",
    "time = sys.clock() - time\n",
    "time = time / n_training_instances\n",
    "print(\"\\n==> time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
    "--ProFi:stop()\n",
    "--ProFi:writeReport( 'profile.txt' )\n",
    "]]--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
