{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--******RUN-1 PARAMETERS*****--\n",
    "\n",
    "---- Instead of 10-way classification its performs BINARY CLASSIFICATION over image pairs\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "require 'nn'\n",
    "require 'cunn'\n",
    "model_utils = require 'model_utils'\n",
    "dofile './provider.lua'\n",
    "c = require 'trepl.colorize'\n",
    "require 'image'\n",
    "require 'csvigo'\n",
    "\n",
    "cmd_params = {}\n",
    "----- from the opt settings ------\n",
    "cmd_params.save = 'logs_stfaction40/vgg_conv_atten_e-7_3levels_1global'\n",
    "cmd_params.batchSize = 128\n",
    "cmd_params.learningRate = 1\n",
    "cmd_params.learningRateDecay = 1e-7\n",
    "cmd_params.weightDecay = 0.0005\n",
    "cmd_params.momentum = 0.9\n",
    "cmd_params.epochStep = 25\n",
    "--[[\n",
    "cmd_params.mlocal_1 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--1.1_vgg_local'\n",
    "cmd_params.mlocal_2 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--1.2_vgg_local'\n",
    "cmd_params.mlocal_3 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--1.3_vgg_local'\n",
    "\n",
    "cmd_params.mglobal_3 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--2.3_vgg_global'\n",
    "\n",
    "cmd_params.matten_1 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--3.1_vgg_atten'\n",
    "cmd_params.matten_2 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--3.2_vgg_atten'\n",
    "cmd_params.matten_3 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--3.3_vgg_atten'\n",
    "\n",
    "cmd_params.mmatch = '../RegionMatching_cifar100/models/3_level_atten_1global/'--4_vgg_match'\n",
    "--]]\n",
    "----------------------------------\n",
    "cmd_params.max_epoch = 300\n",
    "cmd_params.backend = 'nn'\n",
    "cmd_params.type = 'cuda'\n",
    "----------------------------------\n",
    "cmd_params.gpumode = 1\n",
    "cmd_params.gpu_setDevice = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function cast(t)\n",
    "   if cmd_params.type == 'cuda' then\n",
    "      require 'cunn'\n",
    "        gpumode = cmd_params.gpumode\n",
    "        if gpumode==1 then\n",
    "            cutorch.setDevice(cmd_params.gpu_setDevice)\n",
    "        end\n",
    "      return t:cuda()\n",
    "   elseif cmd_params.type == 'float' then\n",
    "      return t:float()\n",
    "   elseif cmd_params.type == 'cl' then\n",
    "      require 'clnn'\n",
    "      return t:cl()\n",
    "   else\n",
    "      error('Unknown type '..cmd_params.type)\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local seed = 1234567890\n",
    "torch.manualSeed(seed)\n",
    "train_or_val = cmd_params.train_or_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "----Data Augmentation\n",
    "function data_aug(input)\n",
    "      local bs = input:size(1)\n",
    "      local flip_mask = torch.randperm(bs):le(bs/2)\n",
    "      for i=1,input:size(1) do\n",
    "        if flip_mask[i] == 1 then image.hflip(input[i], input[i]) end\n",
    "      end    \n",
    "    return input\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m loading data\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  data : FloatTensor - size: 9532x3x32x32\n",
       "  size : function: 0x40ec30e0\n",
       "  labels : DoubleTensor - size: 9532x1\n",
       "}\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " 1\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "----Initiation\n",
    "require 'nngraph'\n",
    "--1. Data loading\n",
    "print(c.blue '==>' ..' loading data')\n",
    "\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/Caltech101/t7_files/caltech101_norm.t7')\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/Caltech256/t7_files/caltech256_norm.t7')  ---sjmod\n",
    "provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/Event8/t7_files/xxxxevent8_whitened.t7')  ---sjmod\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/IndoorSceneRecognition67/t7_files/indoorscenereco67_norm.t7')\n",
    "--provider = torch.load('//media/sjvision/DATASETDISK/Attention_extra_data/data_processed/StanfordAction40/t7_files/stanfordaction40_norm.t7')---sjmod\n",
    "--provider = torch.load('/media/sjvision/01D007501C4F6DD0/2_Codes/TorchCodes/attention_business/ActiveAttention/VGGNet/#dataset/CIFAR10/cifar10_whitened.t7')\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/stl10_matlab_testeddirectlyforaccuracy/t7_files/xxxstl_train_whitenedxx.t7')\n",
    "\n",
    "provider.trainData.data = provider.trainData.data:float()\n",
    "provider.testData.data = provider.testData.data:float()\n",
    "print(provider.testData)\n",
    "itorch.image(provider.testData.data[25]:squeeze())\n",
    "print(provider.testData.labels[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m setting criterion\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Will save at logs_stfaction40/vgg_conv_atten_e-7_3levels_1global\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m configuring optimizer\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "--2. Model creation\n",
    "mlocal1_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mlocal_1.net')\n",
    "mlocal_1 = nn.Sequential()\n",
    "mlocal_1:add(cast(nn.Copy('torch.FloatTensor', torch.type(cast(torch.Tensor())))))\n",
    "--mlocal_1:add(cast(dofile('models/'..cmd_params.mlocal_1..'.lua')))\n",
    "mlocal_1:add(mlocal1_wts)\n",
    "mlocal_1:get(1).updateGradInput = function(input) return end\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "   require 'cudnn'\n",
    "   cudnn.convert(mlocal_1:get(2), cudnn)\n",
    "end\n",
    "\n",
    "mlocal2_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mlocal_2.net')\n",
    "mlocal_2 = nn.Sequential()\n",
    "--mlocal_2:add(cast(dofile('models/'..cmd_params.mlocal_2..'.lua')))\n",
    "mlocal_2:add(mlocal2_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mlocal_2:get(1), cudnn)\n",
    "end\n",
    "\n",
    "mlocal3_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mlocal_3.net')\n",
    "mlocal_3 = nn.Sequential()\n",
    "--mlocal_3:add(cast(dofile('models/'..cmd_params.mlocal_3..'.lua')))\n",
    "mlocal_3:add(mlocal3_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mlocal_3:get(1), cudnn)\n",
    "end\n",
    "-------------------------------------------------------------------------------------------------\n",
    "mglobal3_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mglobal_3.net')\n",
    "mglobal_3 = nn.Sequential()\n",
    "--mglobal_3:add(cast(dofile('models/'..cmd_params.mglobal_3..'.lua')))\n",
    "mglobal_3:add(mglobal3_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mglobal_3:get(1), cudnn)\n",
    "end\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "matten1_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/matten_1.net')\n",
    "matten_1 = nn.Sequential()\n",
    "--matten_1:add(cast(dofile('models/'..cmd_params.matten_1..'.lua')))\n",
    "matten_1:add(matten1_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(matten_1:get(1),cudnn)\n",
    "end\n",
    "\n",
    "matten2_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/matten_2.net')\n",
    "matten_2 = nn.Sequential()\n",
    "--matten_2:add(cast(dofile('models/'..cmd_params.matten_2..'.lua')))\n",
    "matten_2:add(matten2_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(matten_2:get(1),cudnn)\n",
    "end\n",
    "\n",
    "matten3_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/matten_3.net')\n",
    "matten_3 = nn.Sequential()\n",
    "--matten_3:add(cast(dofile('models/'..cmd_params.matten_3..'.lua')))\n",
    "matten_3:add(matten3_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(matten_3:get(1),cudnn)\n",
    "end\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "mmatch_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mmatch.net')\n",
    "mmatch = nn.Sequential()\n",
    "--mmatch:add(cast(dofile('models/' ..cmd_params.mmatch..'.lua')))\n",
    "mmatch:add(mmatch_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mmatch:get(1), 'cudnn')\n",
    "end\n",
    "\n",
    "\n",
    "--3. Criterion\n",
    "print(c.blue'==>' ..' setting criterion')\n",
    "criterion = cast(nn.CrossEntropyCriterion())\n",
    "\n",
    "--4. Testing and saving\n",
    "confusion = optim.ConfusionMatrix(100)\n",
    "print('Will save at '..cmd_params.save)\n",
    "paths.mkdir(cmd_params.save)\n",
    "testLogger = optim.Logger(paths.concat(cmd_params.save, 'test.log'))\n",
    "testLogger:setNames{'% mean class accuracy (train set)', '% mean class accuracy (test set)'}\n",
    "testLogger.showPlot = false\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "--5. Learning settings\n",
    "print(c.blue'==>' ..' configuring optimizer')\n",
    "optimState = {\n",
    "  learningRate = cmd_params.learningRate,\n",
    "  weightDecay = cmd_params.weightDecay,\n",
    "  momentum = cmd_params.momentum,\n",
    "  learningRateDecay = cmd_params.learningRateDecay,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--test_unnorm = torch.load('/home/torrvision/zbs-torch/projects/cifar.torch/cifar100-test.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  -- disable flips, dropouts and batch normalization\n",
    "    mlocal_1:evaluate()\n",
    "    mlocal_2:evaluate()\n",
    "    mlocal_3:evaluate()\n",
    "\n",
    "    mglobal_3:evaluate() \n",
    "    \n",
    "    matten_1:evaluate() \n",
    "    matten_2:evaluate() \n",
    "    matten_3:evaluate() \n",
    "    \n",
    "    mmatch:evaluate()\n",
    "    \n",
    "  print(c.blue '==>'..\" testing\")\n",
    "  local nsamples = provider.testData.data:size(1)\n",
    "  local bs = 1 \n",
    "  print(nsamples)\n",
    "    \n",
    "  fv_output = torch.zeros(nsamples,1280)\n",
    "  for i=1,nsamples,bs do \n",
    "    \n",
    "    local lfeat_1 = mlocal_1:forward(provider.testData.data:narrow(1,i,bs))           \n",
    "    local lfeat_2 = mlocal_2:forward(lfeat_1)           \n",
    "    local lfeat_3 = mlocal_3:forward(lfeat_2)           \n",
    "                      \n",
    "    local gfeat_3 = mglobal_3:forward(lfeat_3)\n",
    "        \n",
    "    local att_con_1 = matten_1:forward({lfeat_1,gfeat_3})\n",
    "    local att_con_2 = matten_2:forward({lfeat_2,gfeat_3})\n",
    "    local att_con_3 = matten_3:forward({lfeat_3,gfeat_3})\n",
    "------------1. Visualizations    \n",
    "    --[[\n",
    "    print(att_con_1[1]:squeeze():double():size())\n",
    "    csvigo.save(string.format('/media/sjvision/DATASETDISK/atest/StanfordAction40/attmaps/attmaps_vgg_100/%03d_%s',i,'level1.txt'),att_con_1[1]:squeeze():double():totable())\n",
    "    csvigo.save(string.format('/media/sjvision/DATASETDISK/atest/StanfordAction40/attmaps/attmaps_vgg_100/%03d_%s',i,'level2.txt'),att_con_2[1]:squeeze():double():totable())\n",
    "    csvigo.save(string.format('/media/sjvision/DATASETDISK/atest/StanfordAction40/attmaps/attmaps_vgg_100/%03d_%s',i,'level3.txt'),att_con_3[1]:squeeze():double():totable())\n",
    "    --[[\n",
    "    itorch.image(image.scale(att_con_1[1]:float(),32,32))\n",
    "    itorch.image(image.scale(att_con_2[1]:float(),32,32))\n",
    "    itorch.image(image.scale(att_con_3[1]:float(),32,32))\n",
    "    itorch.image(provider.testData.data:narrow(1,i,bs))\n",
    "    ]]--\n",
    "--------------\n",
    "    local prediction = mmatch:forward({att_con_1[2], att_con_2[2], att_con_3[2]})  \n",
    "------------3. extract the feature vector\n",
    "    fv_output[i]=(mmatch:get(1).modules[13].output:squeeze():float())\n",
    "------------4. No confusion analysis for labels > 10\n",
    "    --[[\n",
    "    confusion:batchAdd(prediction, provider.testData.labels:narrow(1,i,bs))\n",
    "    confusion:updateValids()\n",
    "    --]]\n",
    "-----------2. Analysing the wrong and right predictions\n",
    "    --[[\n",
    "    print(provider.testData.labels:narrow(1,i,bs))\n",
    "    if confusion.totalValid==0 then\n",
    "        itorch.image(testData:narrow(1,i,bs))\n",
    "        print(i)\n",
    "    end\n",
    "    print('Test accuracy:', confusion.totalValid * 100)\n",
    "    confusion:zero()\n",
    "    --]]\n",
    "------------\n",
    "  end\n",
    "    fv_output = fv_output:totable()\n",
    "    csvigo.save('logs_cifar100models_att3/vgg_atten3_fv.txt',fv_output)\n",
    "    --print('Test accuracy:', confusion.totalValid * 100)\n",
    "    --confusion:zero()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m testing\t\n",
       "9532\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\twriting to file: logs_cifar100models_att3/vgg_atten3_fv.txt\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\twriting done\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1,1 do --cmd_params.max_epoch do\n",
    "  test()\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
