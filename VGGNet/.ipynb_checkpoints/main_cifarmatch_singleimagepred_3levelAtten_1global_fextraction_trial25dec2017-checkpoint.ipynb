{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--******RUN-1 PARAMETERS*****--\n",
    "\n",
    "---- Instead of 10-way classification its performs BINARY CLASSIFICATION over image pairs\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "require 'nn'\n",
    "require 'cunn'\n",
    "model_utils = require 'model_utils'\n",
    "dofile './provider.lua'\n",
    "c = require 'trepl.colorize'\n",
    "require 'image'\n",
    "require 'csvigo'\n",
    "\n",
    "cmd_params = {}\n",
    "----- from the opt settings ------\n",
    "cmd_params.save = 'att3_cifar100_ach'\n",
    "cmd_params.batchSize = 128\n",
    "cmd_params.learningRate = 1\n",
    "cmd_params.learningRateDecay = 1e-7\n",
    "cmd_params.weightDecay = 0.0005\n",
    "cmd_params.momentum = 0.9\n",
    "cmd_params.epochStep = 25\n",
    "--[[\n",
    "cmd_params.mlocal_1 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--1.1_vgg_local'\n",
    "cmd_params.mlocal_2 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--1.2_vgg_local'\n",
    "cmd_params.mlocal_3 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--1.3_vgg_local'\n",
    "\n",
    "cmd_params.mglobal_3 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--2.3_vgg_global'\n",
    "\n",
    "cmd_params.matten_1 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--3.1_vgg_atten'\n",
    "cmd_params.matten_2 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--3.2_vgg_atten'\n",
    "cmd_params.matten_3 = '../RegionMatching_cifar100/models/3_level_atten_1global/'--3.3_vgg_atten'\n",
    "\n",
    "cmd_params.mmatch = '../RegionMatching_cifar100/models/3_level_atten_1global/'--4_vgg_match'\n",
    "--]]\n",
    "----------------------------------\n",
    "cmd_params.max_epoch = 300\n",
    "cmd_params.backend = 'nn'\n",
    "cmd_params.type = 'cuda'\n",
    "----------------------------------\n",
    "cmd_params.gpumode = 1\n",
    "cmd_params.gpu_setDevice = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function cast(t)\n",
    "   if cmd_params.type == 'cuda' then\n",
    "      require 'cunn'\n",
    "        gpumode = cmd_params.gpumode\n",
    "        if gpumode==1 then\n",
    "            cutorch.setDevice(cmd_params.gpu_setDevice)\n",
    "        end\n",
    "      return t:cuda()\n",
    "   elseif cmd_params.type == 'float' then\n",
    "      return t:float()\n",
    "   elseif cmd_params.type == 'cl' then\n",
    "      require 'clnn'\n",
    "      return t:cl()\n",
    "   else\n",
    "      error('Unknown type '..cmd_params.type)\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local seed = 1234567890\n",
    "torch.manualSeed(seed)\n",
    "train_or_val = cmd_params.train_or_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "----Data Augmentation\n",
    "function data_aug(input)\n",
    "      local bs = input:size(1)\n",
    "      local flip_mask = torch.randperm(bs):le(bs/2)\n",
    "      for i=1,input:size(1) do\n",
    "        if flip_mask[i] == 1 then image.hflip(input[i], input[i]) end\n",
    "      end    \n",
    "    return input\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "----Initiation\n",
    "require 'nngraph'\n",
    "--1. Data loading\n",
    "print(c.blue '==>' ..' loading data')\n",
    "\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/Caltech101/t7_files/caltech101_norm.t7')\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/Caltech256/t7_files/caltech256_norm.t7')  ---sjmod\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/Event8/t7_files/xxxxevent8_whitened.t7')  ---sjmod\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/IndoorSceneRecognition67/t7_files/indoorscenereco67_norm.t7')\n",
    "--provider = torch.load('//media/sjvision/DATASETDISK/Attention_extra_data/data_processed/StanfordAction40/t7_files/stanfordaction40_norm.t7')---sjmod\n",
    "--provider = torch.load('/media/sjvision/01D007501C4F6DD0/2_Codes/TorchCodes/attention_business/ActiveAttention/VGGNet/#dataset/CIFAR10/cifar10_whitened.t7')\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/stl10_matlab_testeddirectlyforaccuracy/t7_files/xxxstl_train_whitenedxx.t7')\n",
    "provider = torch.load('/media/sjvision/DATASETDISK/Att_ObjectDiscovery-data/Data/t7_files/objDiscoData_ach_norm.t7')\n",
    "\n",
    "provider.trainData.data = provider.trainData.data:float()\n",
    "provider.testData.data = provider.testData.data:float()\n",
    "print(provider.testData)\n",
    "itorch.image(provider.testData.data[25]:squeeze())\n",
    "print(provider.testData.labels[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "--2. Model creation\n",
    "mlocal1_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mlocal_1.net')\n",
    "mlocal_1 = nn.Sequential()\n",
    "mlocal_1:add(cast(nn.Copy('torch.FloatTensor', torch.type(cast(torch.Tensor())))))\n",
    "--mlocal_1:add(cast(dofile('models/'..cmd_params.mlocal_1..'.lua')))\n",
    "mlocal_1:add(mlocal1_wts)\n",
    "mlocal_1:get(1).updateGradInput = function(input) return end\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "   require 'cudnn'\n",
    "   cudnn.convert(mlocal_1:get(2), cudnn)\n",
    "end\n",
    "\n",
    "mlocal2_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mlocal_2.net')\n",
    "mlocal_2 = nn.Sequential()\n",
    "--mlocal_2:add(cast(dofile('models/'..cmd_params.mlocal_2..'.lua')))\n",
    "mlocal_2:add(mlocal2_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mlocal_2:get(1), cudnn)\n",
    "end\n",
    "\n",
    "mlocal3_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mlocal_3.net')\n",
    "mlocal_3 = nn.Sequential()\n",
    "--mlocal_3:add(cast(dofile('models/'..cmd_params.mlocal_3..'.lua')))\n",
    "mlocal_3:add(mlocal3_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mlocal_3:get(1), cudnn)\n",
    "end\n",
    "-------------------------------------------------------------------------------------------------\n",
    "mglobal3_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mglobal_3.net')\n",
    "mglobal_3 = nn.Sequential()\n",
    "--mglobal_3:add(cast(dofile('models/'..cmd_params.mglobal_3..'.lua')))\n",
    "mglobal_3:add(mglobal3_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mglobal_3:get(1), cudnn)\n",
    "end\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "matten1_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/matten_1.net')\n",
    "matten_1 = nn.Sequential()\n",
    "--matten_1:add(cast(dofile('models/'..cmd_params.matten_1..'.lua')))\n",
    "matten_1:add(matten1_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(matten_1:get(1),cudnn)\n",
    "end\n",
    "\n",
    "matten2_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/matten_2.net')\n",
    "matten_2 = nn.Sequential()\n",
    "--matten_2:add(cast(dofile('models/'..cmd_params.matten_2..'.lua')))\n",
    "matten_2:add(matten2_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(matten_2:get(1),cudnn)\n",
    "end\n",
    "\n",
    "matten3_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/matten_3.net')\n",
    "matten_3 = nn.Sequential()\n",
    "--matten_3:add(cast(dofile('models/'..cmd_params.matten_3..'.lua')))\n",
    "matten_3:add(matten3_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(matten_3:get(1),cudnn)\n",
    "end\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "mmatch_wts = torch.load('#logs/#logs_CIFAR100/3atten_e-7_3levels_1global/mmatch.net')\n",
    "mmatch = nn.Sequential()\n",
    "--mmatch:add(cast(dofile('models/' ..cmd_params.mmatch..'.lua')))\n",
    "mmatch:add(mmatch_wts)\n",
    "if cmd_params.backend == 'cudnn' then\n",
    "    cudnn.convert(mmatch:get(1), 'cudnn')\n",
    "end\n",
    "\n",
    "\n",
    "--3. Criterion\n",
    "print(c.blue'==>' ..' setting criterion')\n",
    "criterion = cast(nn.CrossEntropyCriterion())\n",
    "\n",
    "--4. Testing and saving\n",
    "confusion = optim.ConfusionMatrix(100)\n",
    "print('Will save at '..cmd_params.save)\n",
    "paths.mkdir(cmd_params.save)\n",
    "testLogger = optim.Logger(paths.concat(cmd_params.save, 'test.log'))\n",
    "testLogger:setNames{'% mean class accuracy (train set)', '% mean class accuracy (test set)'}\n",
    "testLogger.showPlot = false\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "--5. Learning settings\n",
    "print(c.blue'==>' ..' configuring optimizer')\n",
    "optimState = {\n",
    "  learningRate = cmd_params.learningRate,\n",
    "  weightDecay = cmd_params.weightDecay,\n",
    "  momentum = cmd_params.momentum,\n",
    "  learningRateDecay = cmd_params.learningRateDecay,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--test_unnorm = torch.load('/home/torrvision/zbs-torch/projects/cifar.torch/cifar100-test.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  -- disable flips, dropouts and batch normalization\n",
    "    mlocal_1:evaluate()\n",
    "    mlocal_2:evaluate()\n",
    "    mlocal_3:evaluate()\n",
    "\n",
    "    mglobal_3:evaluate() \n",
    "    \n",
    "    matten_1:evaluate() \n",
    "    matten_2:evaluate() \n",
    "    matten_3:evaluate() \n",
    "    \n",
    "    mmatch:evaluate()\n",
    "    \n",
    "  print(c.blue '==>'..\" testing\")\n",
    "  local nsamples = provider.testData.data:size(1)\n",
    "  local bs = 1 \n",
    "  print(nsamples)\n",
    "    \n",
    "  fv_output = torch.zeros(nsamples,1280)\n",
    "  for i=1,nsamples,bs do \n",
    "    \n",
    "    local lfeat_1 = mlocal_1:forward(provider.testData.data:narrow(1,i,bs))           \n",
    "    local lfeat_2 = mlocal_2:forward(lfeat_1)           \n",
    "    local lfeat_3 = mlocal_3:forward(lfeat_2)           \n",
    "                      \n",
    "    local gfeat_3 = mglobal_3:forward(lfeat_3)\n",
    "        \n",
    "    local att_con_1 = matten_1:forward({lfeat_1,gfeat_3})\n",
    "    local att_con_2 = matten_2:forward({lfeat_2,gfeat_3})\n",
    "    local att_con_3 = matten_3:forward({lfeat_3,gfeat_3})\n",
    "------------1. Visualizations    \n",
    "  \n",
    "    --print(att_con_1[1]:squeeze():double():size())\n",
    "    csvigo.save(string.format('att3_cifar100_ach/%03d_%s',i,'level1.txt'),att_con_1[1]:squeeze():double():totable())\n",
    "    csvigo.save(string.format('att3_cifar100_ach/%03d_%s',i,'level2.txt'),att_con_2[1]:squeeze():double():totable())\n",
    "    csvigo.save(string.format('att3_cifar100_ach/%03d_%s',i,'level3.txt'),att_con_3[1]:squeeze():double():totable())\n",
    "    --[[\n",
    "    itorch.image(image.scale(att_con_1[1]:float(),32,32))\n",
    "    itorch.image(image.scale(att_con_2[1]:float(),32,32))\n",
    "    itorch.image(image.scale(att_con_3[1]:float(),32,32))\n",
    "    itorch.image(provider.testData.data:narrow(1,i,bs))\n",
    "    ]]--\n",
    "--------------\n",
    "    local prediction = mmatch:forward({att_con_1[2], att_con_2[2], att_con_3[2]})  \n",
    "------------3. extract the feature vector\n",
    "    fv_output[i]=(mmatch:get(1).modules[13].output:squeeze():float())\n",
    "------------4. No confusion analysis for labels > 10\n",
    "    --[[\n",
    "    confusion:batchAdd(prediction, provider.testData.labels:narrow(1,i,bs))\n",
    "    confusion:updateValids()\n",
    "    --]]\n",
    "-----------2. Analysing the wrong and right predictions\n",
    "    --[[\n",
    "    print(provider.testData.labels:narrow(1,i,bs))\n",
    "    if confusion.totalValid==0 then\n",
    "        itorch.image(testData:narrow(1,i,bs))\n",
    "        print(i)\n",
    "    end\n",
    "    print('Test accuracy:', confusion.totalValid * 100)\n",
    "    confusion:zero()\n",
    "    --]]\n",
    "------------\n",
    "  end\n",
    "    fv_output = fv_output:totable()\n",
    "    csvigo.save('att3_cifar100_ach/vgg_atten3_fv.txt',fv_output)\n",
    "    --print('Test accuracy:', confusion.totalValid * 100)\n",
    "    --confusion:zero()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i=1,1 do --cmd_params.max_epoch do\n",
    "  test()\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
