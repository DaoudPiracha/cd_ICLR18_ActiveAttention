{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Code for Wide Residual Networks http://arxiv.org/abs/1605.07146\n",
    "-- (c) Sergey Zagoruyko, 2016\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "c = require 'trepl.colorize'\n",
    "json = require 'cjson'\n",
    "require'augmentation'\n",
    "model_utils = require 'model_utils'   ---sjmod\n",
    "require'provider'\n",
    "require'nngraph'\n",
    "require 'csvigo'\n",
    "\n",
    "-- for memory optimizations and graph generation\n",
    "local optnet = require 'optnet'\n",
    "local graphgen = require 'optnet.graphgen'\n",
    "local iterm = require 'iterm'\n",
    "require 'iterm.dot'\n",
    "\n",
    "opt = {\n",
    "  save = 'logs_vgg-gap100/',\n",
    "  batchSize = 64, --128,\n",
    "  learningRate = 0.1,   ------overwritten\n",
    "  learningRateDecay = 0,   ------overwritten\n",
    "  learningRateDecayRatio = 0.2,   ------overwritten\n",
    "  weightDecay = 0.0005,\n",
    "  dampening = 0,\n",
    "  momentum = 0.9,\n",
    "  epoch_step = \"80\",   ------overwritten\n",
    "  max_epoch = 300,   ------overwritten\n",
    "\n",
    "  model = 'model.t7',\n",
    "\n",
    "  optimMethod = 'sgd',\n",
    "  init_value = 10,\n",
    "  depth = 50,\n",
    "  shortcutType = 'A',\n",
    "  nesterov = false,   ------overwritten\n",
    "  dropout = 0,\n",
    "  hflip = true,\n",
    "  randomcrop = 4,\n",
    "  imageSize = 32,\n",
    "  randomcrop_type = 'zero',   ------overwritten\n",
    "  cudnn_fastest = true,\n",
    "  cudnn_deterministic = false,\n",
    "  optnet_optimize = true,\n",
    "  generate_graph = false,\n",
    "  multiply_input_factor = 1,\n",
    "  widen_factor = 1,\n",
    "}\n",
    "opt = xlua.envparams(opt)\n",
    "\n",
    "opt.epoch_step = tonumber(opt.epoch_step) or loadstring('return '..opt.epoch_step)()\n",
    "--print(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m loading data\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 1\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(c.blue '==>' ..' loading data')\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/cifars/cifar100/cifar100_whitened.t7')\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/ObjectDiscovery-data/ach_100/t7_files/objDiscoData_ach_whitened.t7')\n",
    "provider = torch.load('/media/sjvision/DATASETDISK/Attention_extra_data/data_processed/IndoorSceneRecognition67/t7_files/indoorscenereco67_norm.t7')\n",
    "print(provider.testData.labels[400])\n",
    "itorch.image(provider.testData.data[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m configuring models\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c.blue '==>' ..' configuring models')\n",
    "model = nn.Sequential()\n",
    "net = torch.load('/media/sjvision/01D007501C4F6DD0/2_Codes/TorchCodes/attention_business/ActiveAttention/RESNET/#results/vgg_gap_cifar100_14355834/' ..opt.model):cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do\n",
    "   ------Main Model----------INITIALIZATION-----------------\n",
    "   model:add(nn.Copy('torch.FloatTensor','torch.CudaTensor'):cuda())   \n",
    "   model:add(net) -- adding the network -- sjmod\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.View(512)\n",
       "{\n",
       "  train : false\n",
       "  output : CudaTensor - empty\n",
       "  gradInput : CudaTensor - empty\n",
       "  size : LongStorage - size: 1\n",
       "  numElements : 512\n",
       "  _type : torch.CudaTensor\n",
       "}\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model:get(2):get(51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  \n",
    "    model:evaluate()\n",
    "    --local confusion = optim.ConfusionMatrix(100)\n",
    "    nsamples = provider.testData.data:size(1)\n",
    "    bs = 1 print(nsamples)\n",
    "    fv_output = torch.zeros(nsamples,512)\n",
    "    \n",
    "  for i = 1,nsamples,bs do \n",
    "        local pred = model:forward(provider.testData.data:narrow(1,i,bs))\n",
    "        pred = pred:reshape(1,100)\n",
    "        fv_output[i] = model:get(2):get(51).output:squeeze():float()\n",
    "        --[[\n",
    "        val, ind = torch.max(pred,2)\n",
    "        print(ind)\n",
    "        print(provider.testData.labels[i])       \n",
    "        confusion:batchAdd(pred, provider.testData.labels:narrow(1,i,bs))   ---testing fwd   ---sjmod\n",
    "        confusion:updateValids()\n",
    "        --]]\n",
    "  end\n",
    "    fv_output = fv_output:totable()\n",
    "    csvigo.save('logs_vgg-gap100/vgg_gap100_saction40.txt',fv_output)\n",
    "  return 0 --confusion.totalValid * 100\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function extract_attmaps()\n",
    "  \n",
    "    model:evaluate()  \n",
    "    nsamples = provider.testData.data:size(1)\n",
    "    bs = 1 print(nsamples)\n",
    "        \n",
    "  for i = 101,200,bs do \n",
    "        -- fwd prop through the entire network pipeline\n",
    "        local pred = model:forward(provider.testData.data:narrow(1,i,bs))\n",
    "        -- extract the 3D tensor before GAP\n",
    "        local spatialtensor = model:get(2):get(49).output:squeeze()\n",
    "        -- extract the weight vector for the corresponding class\n",
    "        local classid\n",
    "        if i<=100 then -- airplane - not present - cant work for the classes not trained for\n",
    "        elseif i<=200 then\n",
    "            classid = 82\n",
    "        else -- horse - not present - cant work for the classes not trained for\n",
    "        end\n",
    "        local classwtvec = model:get(2):get(52):get(1).weight[classid]:squeeze()\n",
    "        classwtvec = nn.Replicate(8,2,1):cuda():forward(classwtvec)\n",
    "        classwtvec = nn.Replicate(8,2,1):cuda():forward(classwtvec)\n",
    "        -- obtain the attmaps as the dot product at each spatial location in the 3D tensor\n",
    "        local att_map = nn.CMulTable():cuda():forward({spatialtensor,classwtvec})\n",
    "        att_map = nn.Sum(1,3):cuda():forward(att_map)\n",
    "        -- save the attmap\n",
    "        att_map = att_map:totable()\n",
    "        csvigo.save(string.format('/media/sjvision/DATASETDISK/ObjectDiscovery-data/ach_100/VGG-GAP_100/att_maps_raw/%03d_%s',i,'level2.txt'),att_map)\n",
    "  end\n",
    "\n",
    "  return\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15613\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\twriting to file: logs_vgg-gap100/vgg_gap100_saction40.txt\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\twriting done\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch=1,1 do\n",
    "  local test_acc, test_time =test()  ----sjmod\n",
    "  --extract_attmaps()\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
