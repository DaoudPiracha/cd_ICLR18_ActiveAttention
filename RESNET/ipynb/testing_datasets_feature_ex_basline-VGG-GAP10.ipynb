{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Code for Wide Residual Networks http://arxiv.org/abs/1605.07146\n",
    "-- (c) Sergey Zagoruyko, 2016\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "require 'image'\n",
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "c = require 'trepl.colorize'\n",
    "json = require 'cjson'\n",
    "require'augmentation'\n",
    "model_utils = require 'model_utils'   ---sjmod\n",
    "require'provider'\n",
    "require'nngraph'\n",
    "require 'csvigo'\n",
    "\n",
    "-- for memory optimizations and graph generation\n",
    "local optnet = require 'optnet'\n",
    "local graphgen = require 'optnet.graphgen'\n",
    "local iterm = require 'iterm'\n",
    "require 'iterm.dot'\n",
    "\n",
    "opt = {\n",
    "  save = 'logs_testingvisu/vgg_gap10',\n",
    "  batchSize = 64, --128,\n",
    "  learningRate = 0.1,   ------overwritten\n",
    "  learningRateDecay = 0,   ------overwritten\n",
    "  learningRateDecayRatio = 0.2,   ------overwritten\n",
    "  weightDecay = 0.0005,\n",
    "  dampening = 0,\n",
    "  momentum = 0.9,\n",
    "  epoch_step = \"80\",   ------overwritten\n",
    "  max_epoch = 300,   ------overwritten\n",
    "\n",
    "  model = 'model.t7',\n",
    "\n",
    "  optimMethod = 'sgd',\n",
    "  init_value = 10,\n",
    "  depth = 50,\n",
    "  shortcutType = 'A',\n",
    "  nesterov = false,   ------overwritten\n",
    "  dropout = 0,\n",
    "  hflip = true,\n",
    "  randomcrop = 4,\n",
    "  imageSize = 32,\n",
    "  randomcrop_type = 'zero',   ------overwritten\n",
    "  cudnn_fastest = true,\n",
    "  cudnn_deterministic = false,\n",
    "  optnet_optimize = true,\n",
    "  generate_graph = false,\n",
    "  multiply_input_factor = 1,\n",
    "  widen_factor = 1,\n",
    "}\n",
    "opt = xlua.envparams(opt)\n",
    "\n",
    "opt.epoch_step = tonumber(opt.epoch_step) or loadstring('return '..opt.epoch_step)()\n",
    "--print(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m loading data\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 7\n",
       "[torch.ByteTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAKe0lEQVRIiQXBaYyc50EA4Pf67plvrt3Zndnd2dO7a3ttx/bGsWNlg6O0qVuihKoqImqpGqmo/GglKEKlQv2BhPgThBASAoFECT9ALYeS0sZqnIBVmjqxs4mveO/DuzszO/fMd77v9x48D/zbv/7TzmFdoLSA2MeGIQ9iDlO5TN8TWdzvANpohu2B/sor3/7lg7WjsD45PuTvHWsaKatN1/j6+Ozw3u03/vv//uPV3/nBVOXZrSdbex++f35RkJTu6fmd/Roen5jVgeXkBJSq6+m6BJahAToS9xy/35lyz1pg4uWLL35T3W3U7r+5I4WdpVL7QnX7tedfeOtRJ/ID2tj5/vfeaPbBu2/fpGFm7sJXP3vwmIcsEoWcPoZXlheKY/nqcd+Almn4POOahYyhDODibCmLkT1Iuqu7j8ar4DfmRr/49JzGsIylbgcVtjc2mn4iTORkNw4bv3j75uXnlqbnbM32U3OXbr2/XqlML54+S6Az1E94NqcXhqONzZ3Yz/gd14+qUV8wLZWxYiH4YRe+e+qrH934l+kR/QvZypfT2anJ/l+8s+OcWPa3V+9+9uC3v/36699/TdFAMR/j/sUp98YIXro0xXfWyTEfTvfZdPoYJDkJZg6jERiSZxYzUyPaO/dtw0AFF7CGHai1j2dORgmVLRa3uhM7ouVcuz5/ZvvGP3/vB3+cyFZt/0gkfsJlIef+6E/+8Xdfe7173No86hHDwCdK3mA3ZpD03ZdY59eAtf731sYk2auBp/dqhpEz9LStjzgVEoXZSaRjAOxksDarZT54969Onzmvomi32RgmsjPonbu8fOvWKpiff/DBzwyodRNCmlQ3DdxOQNhJZ8tDgkvdAF/64jc41m3NjoKOhPDdT2tfG3Nu7z16iHKImZI38r1NM6dT7nRQ7nGtXSlNNe+vxgxW9w+2Nmt/+MM/6m7dP1Ec/qe37uGF5SvNnYbpjK/f+1gq+t3fvzozlul5zYNGPaT1ahy7Wbvd8t/8tx9lMpw7KWTlQOQ9ncnuHTQmlq5efW559fZ70YClihOEqKn5yoNPm//5N39/5eJ0v9H7eHuAX33pWcpUwcrozYOnv7Kyvrm22xoceSIKIaMg8ECn3ZmZnS3OLFjj88HxEwkBZXJFV3f3G8WlZRYcF9JZFtU4F0rkHz34eGm2/Po3rk9Ojr7xD/9amp0nOwNIiFPUwMTnV6Rmd329VeuWx4v9uOMUzJQeJzRst/fyI+VJU+7dc1WKCED2qcc1ZyhnHe08cTWzNDa+u72XBF4Yt1Zb3ZBRBjAYmfbpEXqSWCkruvv409TkqbWPdlk3mirZrd0txyBKIQYJNtL9Rgxj9sndT4A7ATFK46N6ciAs3TagroF+P0AwnzKySdxYGp+RVnnl+ZfSBePU3FMeQxhMLCzkLQLzBrFMLAKPZs3YHbINDQRKQcUQTjPPc7PO5uZhXCiaqFlER4NWkwxdLhXNdqOjZ9wwiXSYsZisN3dIbhLruWbfq1cfARKjVy8sBz2wdGGStat3bt8hWLY7cnujPfCpZlqaZvY6nUhg2yjg1GhMOy447Hdb+amVRGAqhEJKGhSbhMYsGsRzF1Z02bz90zdFkh6ZunhxwkTnShMqZNQQBLfyWbsfh0Nz88WFBSc/Xh4e11nT1chIeWLn8YNyLs9pXXDQ70XTc8/3+90EQ2lDmcjIY0iDmvT9UDdGzy1cfcELPQdmP7q9jga0ZuDUxif1XpyuFF2ErfdufiiBHYf0v978SzvQMnoCSTgxM+TLKOxvVKZeTuVOrm3ta0SqMIIRFt2YRxQGgSDAySNs0hCDfApYsG5msmisnCSAhjHpIBOlstc+/9TS0uJ4Ltus/TyTj3xPpoDuaNzN5xBIutW2SXXLGd1Z/+nlk+Vk8MSkDOtGPq33hKGPnNe8aq63bnfWnOAwOFw7V5jDY1BnRtnKjUMVLEwXb/3icdLpDieN9SAsjTpP6jvRYWBBUDnt/vutu8+cWZmUfNCqGjrOFE73xED4sW3lOx72O3FOegfHh5ypIMTMAzBkAR7GX165ltV8o2iko432ZgDzQ2dLYNOLUfaC2R2cKZ/JXzi9F0bv3dmQ+SvlIXfKjhfLxfW1VWNkMjTGQpRG9X3YrTne/vlrJ7lMrHy+UqrUUX9h7vSMQfCpRaPK6IP2cTPSspXLF54p1bbvHxrP2d3+qBw0k/6tsBfGIi/EqXT6YG17c399r78vc0Mp0+LEmZktis33hR/mlq/c+OjhZ51Gx9I91hKBt+E3t++sEVb6nAXIM7ZIuS5SqaPV25vebCqH9ON72fMT+zFcHs6TCA/CHkiThcwwtJ56ErRtTLhi9YdbWeE9eli9+Ju/5xv0xMK4wkTxBHNBSiUrCrTPzeDvfO3llBafWhy9eXO7gmS11hUjC6nNX5UuO37ByRmC8CaRfsGJMGzppsboUTENiqmwU4MmQWOFxOMnuI4c+8jVQBqjFEI6jkxLZh17xJDI91tYS/qN3s9/eefouGM5au/Gj8+/MAzcXNRjMTNAQiS0B9SJpRP4mpJpFsJ4EFo5ANI20qnQeDvoWhaOY+UNEj8isUozKgddz/cJotjxqbSGDCvefurZ0olzhfJY1ofQ93wBNBhyEEqYBFSIJCEQJYDzWJGYERFb/QHBjoq51OAQYZTRBBOkFOM0SYQmEj1RCYp9P+FJtdaYdM9phDIW5BZmdnfblgYh5JwwZtkCKgSYoRSKYywZFL6uIWlk6ttN18Dzp2Y31g/cfFYCKqGkKgAKSooB0jgniOsuS3yTW5e/9Er1uDcIUSqtd3tpESMUe4j6EiFGLIgskGAZCAIMk4FR17z/8Em7XZ+sLH7w6/s03BBaGiVEKazbljIEED2MpQQMgbjpMHwUmqHGJe9JLizXjGwlJFGaiSwdRwEIE00wrGOVywvHpLqAFrF4uzLEIuCsvvPet77+bKvFka4hDYuIE5ZI02FcIYKQ7gzruRK1y9ikBrZhwoUG9a17ypcQWgm2JdaFjhWQNOkxFMdBz0J6CER5eOjUyqt//mc/+4MffiXEoHNclxBIv49gjIUGkwAqKiQieqO2ttUkJzHdPsi8dHb/Jzd79uDs5TMR0WQioAakEIYwEU74gGNCspm8GIiNHZieWPzVWx9eumTmxtNHtToxHQVwgjSgegAJqVIIKSkxUhKro0ausXP6aiWgkVrfOeGkeSY78D2E9KhDE8MVtimAZZbLSNNztvn23/344H9u92Xmxesj4yXRaA44taNqhweeUhxgO6JcN3WuJZqe4Bevr4wvz5CUS6Ok2TgsXrvCM0aAAUQSQo4SBqGmeGAakParEGqAoELaWjg/tR1kzCHTVjUvVkLJTCYtIIKSQi6R6QolUBzJ0MOX5k/GEQgZEN0jixg05BxROJBJfdDfOrCyeQSkhXHz4Z4G00bGiNv94tyM4i3JmveaYynEjKhNMGKUMQSRhg3dSGIqw5jYlumk8NVXfisYu84z05g2bIdGigtNVww4Izl7zJUmhErGiruVUS2tKy5kErJeGymQSRnd3Y1yySZKcWzopo4UJBpRjGPaw0hgJaBh/T9DXOe0FI5oMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(c.blue '==>' ..' loading data')\n",
    "\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/cifars/Cifar10/cifar10_whitened_orig.t7')\n",
    "\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/atest/Event8/t7_files/event8_whitened.t7')  ---sjmod\n",
    "provider = torch.load('/media/sjvision/DATASETDISK/atest/Caltech101/t7_files/caltech101_whitened.t7')  ---sjmod\n",
    "--provider = torch.load('/media/sjvision/DATASETDISK/atest/IndoorSceneRecognition67/t7_files/indoorscenereco67_whitened.t7')\n",
    "\n",
    "\n",
    "print(provider.testData.labels[55])\n",
    "itorch.image(provider.testData.data[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;34m==>\u001b[0m configuring models\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c.blue '==>' ..' configuring models')\n",
    "model = nn.Sequential()\n",
    "net = torch.load('logs/vgg_gap_cifar10_3253931374/' ..opt.model):cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do\n",
    "   ------Main Model----------INITIALIZATION-----------------\n",
    "   model:add(nn.Copy('torch.FloatTensor','torch.CudaTensor'):cuda())   \n",
    "   model:add(net) -- adding the network -- sjmod\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model:get(2):get(49))\n",
    "print(model:get(2):get(52):get(1).weight:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  \n",
    "    model:evaluate()\n",
    "    local confusion = optim.ConfusionMatrix(10)\n",
    "    \n",
    "    nsamples = provider.testData.data:size(1)\n",
    "    bs = 1 print(nsamples)\n",
    "    --fv_output = torch.zeros(nsamples,512)\n",
    "    \n",
    "  for i = 1,nsamples,bs do \n",
    "        local pred = model:forward(provider.testData.data:narrow(1,i,bs))\n",
    "        pred = pred:reshape(1,10)\n",
    "        --fv_output[i] = model:get(2):get(51).output:squeeze():float()\n",
    "        --[[\n",
    "        val, ind = torch.max(pred,2)\n",
    "        print(ind)\n",
    "        print(provider.testData.labels[i])       \n",
    "        confusion:batchAdd(pred, provider.testData.labels:narrow(1,i,bs))   ---testing fwd   ---sjmod\n",
    "        confusion:updateValids()\n",
    "        --]]\n",
    "\n",
    "  end\n",
    "    --print(confusion.totalValid * 100)\n",
    "    --fv_output = fv_output:totable()\n",
    "    --csvigo.save('logs_objectdiscoverydata/vgg_gap10.txt',fv_output)\n",
    "  return 0 --confusion.totalValid * 100\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function extract_attmaps()\n",
    "  \n",
    "    model:evaluate()  \n",
    "    nsamples = 2000 --provider.testData.data:size(1)\n",
    "    bs = 1 print(nsamples)\n",
    "        \n",
    "  for i = 1,nsamples,bs do \n",
    "        -- fwd prop through the entire network pipeline\n",
    "        local pred = model:forward(provider.testData.data:narrow(1,i,bs))\n",
    "        -- extract the 3D tensor before GAP\n",
    "        local spatialtensor = model:get(2):get(49).output:squeeze()\n",
    "        -- extract the weight vector for the corresponding class\n",
    "        local classid\n",
    "        if i<=100 then -- airplane=1\n",
    "            classid = 1\n",
    "        elseif i<=200 then --cat=4\n",
    "            classid = 4\n",
    "        else --horse=8\n",
    "            classid = 8\n",
    "        end\n",
    "        print(classid)\n",
    "        local classwtvec = model:get(2):get(52):get(1).weight[classid]:squeeze()\n",
    "        classwtvec = nn.Replicate(8,2,1):cuda():forward(classwtvec)\n",
    "        classwtvec = nn.Replicate(8,2,1):cuda():forward(classwtvec)\n",
    "        -- obtain the attmaps as the dot product at each spatial location in the 3D tensor\n",
    "        local att_map = nn.CMulTable():cuda():forward({spatialtensor,classwtvec})\n",
    "        att_map = nn.Sum(1,3):cuda():forward(att_map)\n",
    "        -- save the attmap\n",
    "        att_map = att_map:totable()\n",
    "        csvigo.save(string.format('/media/sjvision/DATASETDISK/ObjectDiscovery-data/ach_100/VGG-GAP_10/att_maps_raw/%03d_%s',i,'level2.txt'),att_map)\n",
    "  end\n",
    "\n",
    "  return\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "43.24\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch=1,1 do\n",
    "  --local test_acc, test_time =test()  ----sjmod\n",
    "  extract_attmaps()  \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
