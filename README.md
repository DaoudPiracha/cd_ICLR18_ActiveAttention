# ActiveAttention
Active attention in classification networks: Attention that is optimised at the time of model training.

This code is built on top of:
1. https://github.com/szagoruyko/cifar.torch
In particular the training parameters for VGG network can be found here - https://github.com/szagoruyko/cifar.torch/blob/master/train.lua 

2. https://github.com/szagoruyko/wide-residual-networks/tree/fp16
